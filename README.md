# A-B-Testing-For-Mobile-Game

This repository contains the analysis and implementation of an A/B Testing experiment for a mobile game application. The purpose of the experiment is to optimize game features and enhance user engagement based on statistical testing and data-driven decisions.

## Project Overview

A/B Testing is a controlled experiment comparing two or more variants to determine which version performs better based on a predefined metric. This project analyzes game user data to evaluate feature performance, aiming to:
* Increase user retention
* Boost in-game purchases
* Improve overall user experience

## Technologies Used
* Pandas & NumPy: Data manipulation and analysis
* Matplotlib & Seaborn: Data visualization
* Scipy & Statsmodels: Statistical testing and hypothesis validation

## Key Concepts

* Data Preprocessing:
  - Cleaning and structuring raw game data for analysis.
  - Handling missing values and encoding categorical features.
* Hypothesis Testing:
  - Formulating null and alternative hypotheses.
  - Performing t-tests and chi-square tests for feature comparison.
* Results Analysis:
  - Interpreting p-values and confidence intervals.
  - Making data-driven decisions based on statistical evidence.

## Results and Insights
The experiment results are documented in the notebook, highlighting significant differences between the test groups. Key findings include:
* Impact of feature changes on user engagement.
* Statistical significance of A/B test results.
* Recommendations for game optimization.

